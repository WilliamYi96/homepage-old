<!-- <!DOCTYPE html> -->
<html lang="en">
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>Kai Yi, SE senior student focused on Computer vision & Machine Learning</title>

    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <!-- Le styles -->
    <link href="./assets_files/bootstrap.min.css" rel="stylesheet">
    <link href="./assets_files/bootstrap-responsive.min.css" rel="stylesheet">
    <link href="./assets_files/yangqing.css" rel="stylesheet">

    <!-- Le HTML5 shim, for IE6-8 support of HTML5 elements -->
    <!--[if lt IE 9]>
    <script src="assets/js/html5shiv.js"></script>
    <![endif]-->
    <link rel="icon" href="./assets_files/favicon.ico">
</head>

<div class="visible-phone" id="blackBar">
    <a href="#top">About</a>
    <!--<a href="#research">Research</a>-->
    <a href="#publications">Publications</a>
    <a href="#projects">Projects</a>
    <!--<a href="#teaching">Teaching</a>-->
    <a target="_blank"
       href="https://nbviewer.jupyter.org/github/WilliamYi96/williamyi96.github.io/blob/master/papers/cv_kaiyi.pdf">CV</a>
</div>

<body>

<div class="container span3 hidden-phone">
    <div id="floating_sidebar" class="span3">
        <!-- We use a fancy nav bar if there is enough space -->
        <!--<hr class="hidden-phone">-->
        <br>
        <ul class="nav nav-list bs-docs-sidenav hidden-phone">
            <li><a href="#top">About</a></li>
            <!--<li><a href="#research">Research</a></li>-->
            <li><a href="#publications">Publications</a></li>
            <li><a href="#projects">Projects</a></li>
            <!--<li><a href="#teaching">Teaching</a></li>-->
            <li><a target="_blank"
                   href="https://nbviewer.jupyter.org/github/WilliamYi96/williamyi96.github.io/blob/master/papers/cv_kaiyi.pdf">CV</a>
            </li>
        </ul>
        <hr class="hidden-phone">
        <div class="text-center hidden-phone">
            <img src="assets_files/me.jpg" alt="photo" class="logo-image">
            <br><br>
            williamyi96 AT gmail.com <br>
        </div>

        <!-- Otherwise, we simply use a flat list of links -->

    </div>
</div>


<div class="container">

    <div class="row">

        <div class="span9">
            <br>
            <h3>
                    Kai Yi (易凯)
            </h3>
            <h5>
                williamyi96 AT gmail.com</a>
            </h5>
            <!-- Do I want to show a pic on the phone screen?
            <div class="text-center visible-phone">
                <img src="assets/img/Yihui.png" alt="photo" width="150px"/>
            </div>
            -->
            <a class="visible-phone pull-left" href="http://daggerfs.com/index.html#">
                <img class="media-object" src="assets_files/me.png" width="96px" style="margin: 0px 10px">
            </a>
            <p>
                I'm a senior student from Xi'an Jiaotong University with a speciality of Software Engineering. Now, I intend to pursue PHD studies and my research interests include cognition-based artificial intelligence, machine learning, computer vision and computational psychology.
            </p>
            <p>
                I've been interning at <a target="_blank" href="http://www.aiar.xjtu.edu.cn/"> IAIR </a>(Institute of Artificial Intelligence and Robotics) supervised by Prof. <a target="_blank" href="http://www.aiar.xjtu.edu.cn/info/1015/1071.htm"> Nanning Zheng</a> since July, 2017 and <a target="_blank" href="http://gr.xjtu.edu.cn/web/yufeng/lab">Moral Psycholoy Lab</a> supervised by Prof. Liang Zhao and Prof. <a target="_blank" href="http://gr.xjtu.edu.cn/web/yufeng/english-version">Feng Yu</a> since March, 2018. Now, I just join the lab of <a target="_blank" href="http://www.aafie.org/">AAFIE</a>. Previously I interned at <a target="blank" href="http://nskeylab.xjtu.edu.cn/site/lab/">NEKEY lab</a> (Ministry of Education Key Lab for Intelligent Networks and Network Security) supervised by Senior Engineer <a target="_blank" href="http://eie.xjtu.edu.cn/jgxxx.jsp?urltype=tree.TreeTempUrl&wbtreeid=1285&teacherid=1410"> Jing Tao</a> and Software Institite Innovative Lab in Xi'an Jiaotong University supervised by <a target="_blank" href="http://gr.xjtu.edu.cn/web/zyl"> Yulong Zhang</a>.<p>

        <p>I ever served as a reviewer for ITSC18 (The 21st IEEE International Conference on Intelligent Transportation Systems). </p>
                <p><strong>Planning to pursue a PhD degree. If you're interested in me, please don’t hesitate to contact me.</strong> Here's my <a target="_blank"
                            href="https://nbviewer.jupyter.org/github/WilliamYi96/williamyi96.github.io/blob/master/papers/cv_kaiyi.pdf">CV</a>.
            </p>


            <!--
             *** Research ***
            -->
            <!--<h3>-->
            <!--<a name="research"></a> Research-->
            <!--</h3>-->
            <!--<p>-->
            <!--My current research topics include:-->
            <!--</p><ul>-->
            <!--<li> Learning better structures for image feature extraction.-->
            <!--</li><li> Explaining human generalization behavior with visually grounded cogscience models.-->
            <!--</li><li> Making large-scale vision feasible and affordable.-->
            <!--</li></ul>-->
            <!--<p></p>-->
            <!--<p> (Most recent publications to be added) </p>-->


            <!--
             *** Publications ***
            -->
            <h3>
                <a name="publications"></a> Publications
            </h3>
            <p>
                Link to <a target="_blank"
                                           href="https://scholar.google.com/citations?user=r08j39wAAAAJ"
                                           target="_blank">[Google Scholar]</a>
                <!--<a href="projects.html"> [Unpublished Projects]</a>-->
            </p>
        <div class="media">
                <a class="pull-left">
                    <img class="media-object" src="./assets_files/cbdl.png" width="192px" height="128px">
                </a>
                <div class="media-body">
                    <p class="media-heading">
                        <strong>
                                Cognition-Based Deep Learning: Progresses and Perspectives
                     </strong><br>
                        <strong>Kai Yi</strong>, Shitao Chen, Yu Chen, Chao Xia, <a target="_blank" href="http://www.aiar.xjtu.edu.cn/info/1015/1071.htm"> Nanning Zheng</a>, <strong>14th International Conference on Artificial Intelligence Applications and Innovations (AIAI 2018), Rhodes, Greece</strong>
                        <a target="_blank"
                           href="https://link.springer.com/chapter/10.1007/978-3-319-92007-8_11">[Paper]</a>  
                        
                    </p>
                    <p class="abstract-text">
                            The human brain is composed of multiple modular subsystems, with a unique way interacting among each other. These subsystems have their own unique characteristics and interact to support cognitive functions such as memory, attention and cognitive control. Nowadays, deep learning methods based on the above-mentioned functions accompanied with knowledge are widely used to design more dynamic, robust and powerful systems. We first review and summarize the progresses of cognition-based deep neural networks, and how cognitive mechanisms can be applied to more brain-like neural networks. Then we propose a general framework for the design of cognition-based deep learning system. Although great efforts have been made in this field, cognition-based deep learning is still in its early age. We put forward the potential directions towards this field, such as associative memory in deep learning, interpretable network with cognitive mechanisms, and deep reinforcement learning based on cognitive science.
                    </p>
                </div>
            </div>              
        <div class="media">
                <a class="pull-left">
                    <img class="media-object" src="./assets_files/kbrann.png" width="192px" height="128px">
                </a>
                <div class="media-body">
                    <p class="media-heading">
                        <strong>
                         Knowledge-based Recurrent Attentive Neural Network for Small Object Detection
                     </strong><br>
                        <strong>Kai Yi*</strong>, Zhiqiang Jian*, Shitao Chen, Yuedong Yang, <a target="_blank" href="http://www.aiar.xjtu.edu.cn/info/1015/1071.htm"> Nanning Zheng</a>, <strong>IEEE Transactions on Image Processing (TIP) in submission</strong>
                        <a target="_blank"
                           href="https://arxiv.org/abs/1803.05263">[arXiv]</a>       
                    </p>
                    <p class="abstract-text">
                            Accurate Traffic Sign Detection (TSD) can help intelligent systems make better decisions according to the traffic regulations. TSD, regarded as a typical small object detection problem in some way, is fundamental in Advanced Driver Assistance Systems (ADAS) and self-driving. However, although deep neural networks have achieved human even superhuman performance on several tasks, due to their own limitations, small object detection is still an open question. In this paper, we proposed a brain-inspired network, named as KB-RANN, to handle this problem. Attention mechanism is an essential function of our brain, we used a novel recurrent attentive neural network to improve the detection accuracy in a fine-grained manner. Further, we combined domain specific knowledge and intuitive knowledge to improve the efficiency. Experimental result shows that our methods achieved better performance than several popular methods widely used in object detection. More significantly, we transplanted our method on our designed embedded system and deployed on our self-driving car successfully.
                    </p>
                </div>
            </div>   
                <div class="media">
                <a class="pull-left">
                    <img class="media-object" src="./assets_files/albg.png" width="192px" height="192px">
                </a>
                <div class="media-body">
                    <p class="media-heading">
                        <strong>Affine LBG Algorithm for Codebook Training of Univariate Linear Approximation</strong><br>
                        Tiannan Dong, Jianji Wang, Meng Yang, <strong>Yi Kai</strong>, Nanning Zheng, <strong>6th IEEE Global Conference on Signal and Information Processing (GlobalSIP 18), Anaheim, California, USA</strong>
                        <a target="_blank"
                           href="https://nbviewer.jupyter.org/github/WilliamYi96/williamyi96.github.io/blob/master/papers/A-LBG.pdf?flush_cache=true/">[Paper Coming Soon]</a> 
                    </p>
                    <p class="abstract-text">
                        LBG algorithm is a simple and effective method to train codebook for vector quantization. After LBG was proposed, several interesting algorithms were published to improve the effectiveness and efficiency of LBG. Unlike vector quantization, univariate linear approximation is another important data compression method, which approximates a target vector by a linear transformation of a selected codeword from codebook. Many applications also use LBG or K-means algorithm to train the codebook for univariate linear approximation. In this paper, we proposed an improved LBG algorithm called the affine LBG algorithm to train the codebook for univariate linear approximation. The experimental results show that the affine LBG algorithm can derive a more effective codebook than LBG algorithm for univariate linear approximation. Moreover, the ALBG algorithm is more efficient than LBG algorithm.
                    </p>
                </div>
            </div>
        <!-- <div class="media">
                <a class="pull-left">
                    <img class="media-object" src="./assets_files/filterwise.png" width="96px" height="96px">
                </a>
                <div class="media-body">
                    <p class="media-heading">
                        <strong>
                             Pruning Very Deep Neural Network Channels for Efficient Inference
                     </strong><br>
                        <strong>Yihui He</strong>, Xiangyu Zhang, <a target="_blank" href="http://jiansun.org/">Jian Sun</a>
                        , <i>TPAMI, Major Revision</i>
                    </p>
                    <p class="abstract-text">
                        Channel Pruning is further expanded to Filterwise Pruning with rich experiements.
                    </p>
                </div>
            </div>
            <div class="media">
                <a class="pull-left">
                    <img class="media-object" src="./assets_files/superres.png" width="96px" height="96px">
                </a>
                <div class="media-body">
                    <p class="media-heading">
                        <strong>
                            Single Image Super-resolution with a Parameter Economic Residual-like Convolutional Neural Network
                        </strong><br>
                        Yudong Liang, Ze Yang, Kai Zhang, <strong>Yihui He</strong>, Jinjun Wang, Nanning Zheng, <i>TMM in submission</i>
                        <a target="_blank"
                           href="https://arxiv.org/abs/1703.08173">[arXiv]</a>
                    </p>
                    <p class="abstract-text">
                        This paper aims to extend the merits of residual network, such as skip
                        connection induced fast training, for a typical low-level vision problem,
                        i.e., single image super-resolution. In general, the two main challenges
                        of existing deep CNN for supper-resolution lie in the gradient exploding/vanishing
                        problem and large amount of parameters or computational
                        cost as CNN goes deeper. Correspondingly, the skip connections or identity
                        mapping shortcuts are utilized to avoid gradient exploding/vanishing
                        problem. To tackle with the second problem, a parameter economic CNN
                        architecture which has carefully designed width, depth and skip connections
                        was proposed. Different residual-like architectures for image superresolution
                        has also been compared. Experimental results have demonstrated
                        that the proposed CNN model can not only achieve state-of-the-art
                        PSNR and SSIM results for single image super-resolution but also produce
                        visually pleasant results.
                    </p>
                </div>
            </div>    


            <!--<div class="media">-->
            <!--<a class="pull-left" href="#top">-->
            <!--<img class="media-object" src="./assets_files/decaf-features.png" width="96px" height="96px">-->
            <!--</a>-->
            <!--<div class="media-body">-->
            <!--<p class="media-heading">-->
            <!--<strong>DeCAF: A Deep Convolutional Activation Feature for Generic Visual Recognition</strong><br>-->
            <!--J Donahue, Y Jia, O Vinyals, J Hoffman, N Zhang, E Tzeng, T Darrell. arXiv preprint.<br>-->
            <!--<a target="_blank" href="http://arxiv.org/abs/1310.1531">[ArXiv Link]</a>-->
            <!--<a target="_blank" href="http://decaf.berkeleyvision.org/">[Live Demo]</a>-->
            <!--<a target="_blank" href="https://github.com/UCB-ICSI-Vision-Group/decaf-release/">[Software]</a>-->
            <!--<a target="_blank" href="http://www.eecs.berkeley.edu/~jiayq/decaf_pretrained/">[Pretrained ImageNet Model]</a>-->
            <!--</p>-->
            <!--<p class="abstract-text">-->
            <!--We evaluate whether features extracted from the activation of a deep convolutional network trained in a fully supervised fashion on a large, fixed set of object recognition tasks can be re-purposed to novel generic tasks. We also released the software and pre-trained network to do large-scale image classification.-->
            <!--</p>-->
            <!--</div>-->
            <!--</div>-->

            <!--
             *** Projects ***
            -->
            <h3>
                <a name="projects"></a> Projects
            </h3>
            Link to my <a target="_blank" href="https://github.com/williamyi96">[github public projects]</a>

            <div class="media">
                <a class="pull-left">
                    <img class="media-object"
                         src="./assets_files/CR.png"
                         width="192px" height="128px">
                </a>
                <div class="media-body">
                    <p class="media-heading">
                        <strong>
                            Hierarchical Conceptual Rotation of Mental Knowledge Representation
                        </strong>
                        <a target="_blank"
                           href="https://nbviewer.jupyter.org/github/WilliamYi96/Biological-Network-Alignment-public/blob/master/Network-Alignment.pdf">[PDF]</a>
                           <a target="_blank"
                           href="https://nbviewer.jupyter.org/github/WilliamYi96/williamyi96.github.io/blob/master/papers/ConceptualRotation-Defence.pdf">[Slide]</a>
                    </p>
                    <p class="abstract-text">
In this paper, we proposed a novel hierarchical conceptual rotation theory to explain the knowledge representation of mental. We maintain the perception and the procedure of similarity-matching is motivated by a hierarchical manner. Two key roles are hierarchical representation of knowledge and conceptual rotation. The former is composed of four different levels, with the perception procedure goes further, the degree of abstraction goes deeper. Besides, the latter consists of three stages, they are the manipulations of visual
mental imagery. Experiment is specially designed to prove the widely accepted phenomenon of hierarchical structure also exists in the process of mental imagery. Further, the discover of hierarchical mental imagery may help a lot to the further study of the procedure of learning and perception of we human. What’s more, as this structure shows highly similarity with the procedure of human cognition, the proposed novel framework of the manipulation of perception may help to build more human-alike and dynamic artificial intelligence systems.
                    </p>
                </div>
            </div>

            <div class="media">
                <a class="pull-left">
                    <img class="media-object"
                         src="./assets_files/network-alignment.png"
                         width="192px" height="192px">
                </a>
                <div class="media-body">
                    <p class="media-heading">
                        <strong>
                        Graph Theory Applied to Biological Network Alignment
                        </strong>
                        <a target="_blank"
                           href="https://github.com/WilliamYi96/Biological-Network-Alignment-public">[Website]</a>
                        <a target="_blank" href="https://github.com/WilliamYi96/Biological-Network-Alignment-public/blob/master/Network-Alignment.pdf">[PDF]</a>
                    </p>
                    <p class="abstract-text">
Graph theories are popular among a lot of fields. In this paper, we will review their usages on solving the problem of biological network alignment. Due to the fact that this paper is exactly the solution of the open question from Professor Hayes’ homepage, after reviewing those mentioned above, we will mainly talk about the design principle, fundamental ideas and experiments of the task. In order to show our results more friendly, I visualized them by using Python and Mathematica respectively.
                    </p>
                </div>
            </div>

            <div class="media">
                <a class="pull-left">
                    <img class="media-object"
                         src="./assets_files/healthcare.png"
                         width="192px" height="192px">
                </a>
                <div class="media-body">
                    <p class="media-heading">
                        <strong>
                         Research and system implementation of personalized speech synthesis for alleviating loneliness in the elderly
                        </strong>
                        <a target="_blank" href="https://nbviewer.jupyter.org/github/WilliamYi96/williamyi96.github.io/blob/master/papers/HealthCare.pdf">[PDF]</a>
                        <a target="_blank"
                           href="https://nbviewer.jupyter.org/github/WilliamYi96/williamyi96.github.io/blob/master/papers/HealthCare-Defence.pdf">[Slide]</a>
                    </p>
                    <p class="abstract-text">
                            Recently, the degree of aging in our country has increased, and the problem of loneliness in the elderly has
                            been of vital importance. Our project aims at alleviating the problem of loneliness in the elderly by providing efficient methods such as quering and reminding functions through personalized speech synthesis. Research experiments have shown that the intended audience has a generally positive attitude toward our products, and it is believed that the function of the product contributes to the relief of loneliness. We
                            intend to promote the product in the form of an APP in the early stage. We will consider contacting hardware manufacturers in the later period and provide this service to specialized embedded devices such as bracelet.
                            
                            <br>

                            This paper is divided into several different parts as follows. The first part first explained the basis of the project and its implementation background, and explained the universality of loneliness, the urgency of resolving the problem of loneliness in the elderly. Further, we will illustrate the acceptability and generalizability of our product through detailed literature data and field research reports. The second part of the next section analyzes the essential techniques and model architecture of the project, highlighting the technical features of several different modules such as product speaker recognition, factor modeling, strong voice interaction, and the proposed solution. The third part, as a separate chapter, emphasizes the issues related to server design and development. After fully investigating the current implementation of database engineering, it carefully analyzes the different stages of server design and implementation, and applies this concept to the process. Instruct the server to build and maintain the entire stage. In the fourth part, the
                            output of the project acceptance node is explained from two different perspectives: scientific research achievement and engineering achievement. Among them, the team members are the core, and around the technical key points and difficulties of the project. The project has successfully built and deployed on the server, and completed the first phase of Android application development. Due to the fact that the project is problem oriented towards commercial applications, we have carefully and rigorously applied to various aspects of commercialization such as marketing, personnel management, and risk control. What’s more, we will analyse the high demand, scalability, and profitability of the project.
                    </p>
                </div>
            </div>

            <div class="media">
                <a class="pull-left">
                    <img class="media-object"
                         src="./assets_files/feature-extraction.png"
                         width="192px" height="192px">
                </a>

                <div class="media-body">
                    <p class="media-heading">
                        <strong>Feature extraction by using SITF and BoF</strong> 
                        <a target="_blank" href="https://github.com/WilliamYi96/SIFT-BoF">[SourceCode]</a>
                        <a target="_blank"
                                   href="https://nbviewer.jupyter.org/github/WilliamYi96/williamyi96.github.io/blob/master/papers/HODHNN-P1.pdf">[Part Derivation]</a>
                    </p>
                    <p class="abstract-text">
                        In order to find good patterns in the field of associative memory, we conduct feature extraction by using SIFT and BoF. Further research will classify objects based on HODHNN (High-Order Discrete Hopfield Neural Network) by utilizing the extracted features. 
                    </p>
                </div>
            </div>

            <div class="media">
                <a class="pull-left">
                    <img class="media-object"
                         src="./assets_files/nn.png" width="192px" height="192px">
                </a>

                <div class="media-body">
                    <p class="media-heading">
                        <strong>Neural Network Compression and Acceleration: An Overview</strong> 
                        <a target="_blank" href="https://nbviewer.jupyter.org/github/WilliamYi96/williamyi96.github.io/blob/master/papers/NN-Compression-Survey.pdf">[PDF]</a>
                    </p>
                    <p class="abstract-text">
                        A large number of fields (e.g. natural language processing, computer vision) have
                            witnessed the power of deep convolutional neural networks(CNN). However, both
                            training and doing inference are computationally expensive and memory intensive.
                            Therefore, a growing number of researches are attempting to compress convolutional neural networks, which aimed at accelerating CNN-based models without
                            losing accuracy. These techniques are roughly categorized into four schemes: neural network configuration reset, parameter pruning and sharing, low-rank factorization and sparsity, and knowledge distillation. For methods of each scheme, we
                            provide a roughly insightful analysis regarding their performance, related applications, advantages and drawbacks. After that, we survey the evaluation benchmarks
                            and datasets. Finally, we conclude this paper, discuss remaining challenges and
                            our opinions about the direction in this topic.
                    </p>
                </div>
            </div>

            <!-- <div class="media">
                <a class="pull-left">
                    <img class="media-object" src="./assets_files/shuttle.png" width="96px" height="96px">
                </a>
                <div class="media-body">
                    <p class="media-heading">
                        <strong>shuttlecock detection and tracking</strong>
                        <a target="_blank"
                                   href="https://github.com/yihui-he/Badminton-Robot">[Code]</a>
                    </p>
                    <p class="abstract-text">
                        With guassian mixture model, I extract shuttlecock proposals. Then I use Partical filter to
                        refine proposals. From multi view cameras, I employed
                        structure from motion to predict its 3D location. Combined with Physics laws, landing location
                        prediction accuracy is around 5 cm. (This system
                        works on embeded linux with openCV)
                    </p>
                </div>
            </div> --> 
            <!-- Footer
            ================================================== -->
            <hr>
            <!-- <footer class="footer">
                <div class='hidden-phone'>
                <h3 class="text-center"><a name="wall"></a><strong>works</strong></h3>
                <section id="photos">
                    <img src="https://raw.githubusercontent.com/yihui-he/lip-tracking-with-snake-active-contour-and-particle-filter/master/pic.png"/>
                    <img src="https://raw.githubusercontent.com/yihui-he/Edge-detection-with-zero-crossing/master/lena_1.bmp"/>
                    <img src="https://raw.githubusercontent.com/yihui-he/3D-reconstruction/master/result/selfff.png"/>
                    <img src="./assets_files/cs188.png"/>
                    <img src="https://raw.githubusercontent.com/yihui-he/my-Notes/master/person.jpg.png"/>
                    <img src="http://students.iitk.ac.in/robocon/images/sliders/master/bg-5.jpg"/>
                    <img src="./assets_files/vehicle.png"/>
                    <img src="https://raw.githubusercontent.com/yihui-he/Depth-estimation-with-neural-network/master/presentation/stereo.png?token=AJkBS_A-YWaMd9vcgEQuaXQWe9wmjtTBks5XWM07wA%3D%3D"/>
                    <img src="https://raw.githubusercontent.com/yihui-he/deep-learning-guide/master/presentation/resnet.png"/>
                    <img src="https://raw.githubusercontent.com/yihui-he/deep-learning-guide/master/presentation/kmeans.jpg"/>
                    <img src="./assets_files/shuttle.png"/>
                    <img src="https://raw.githubusercontent.com/yihui-he/my-Notes/master/gaoxin.jpg"/>
                    <img src="https://raw.githubusercontent.com/yihui-he/my-Notes/master/artwork.jpg"/>
                    <img src="https://raw.githubusercontent.com/yihui-he/my-Notes/master/bop.jpg"/>
                    <img src="./assets_files/ocsi.png"/>
                </section>
                
                <a target="_blank" href="https://github.com/yihui-he/panorama"><img
                        src="https://github.com/yihui-he/panorama/blob/master/results/yellowstone5.jpg?raw=true"></a>
                <hr>
                </div>
                <div class="row">
                    <div class="span12">
                        <p>
                            modified from <a target="_blank" href="http://daggerfs.com/">© Yangqing Jia 2013</a>
                        </p>
                    </div>
                </div> -->

            <!-- </footer> -->
        </div>
    </div>
</div>
</body>
</html>

<!-- Le javascript
================================================== -->
<!-- Placed at the end of the document so the pages load faster -->
<!--
    <script type="text/javascript" src="http://platform.twitter.com/widgets.js"></script>
    <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
    <script src="assets/js/bootstrap-transition.js"></script>
    <script src="assets/js/bootstrap-alert.js"></script>
    <script src="assets/js/bootstrap-modal.js"></script>
    <script src="assets/js/bootstrap-dropdown.js"></script>
    <script src="assets/js/bootstrap-scrollspy.js"></script>
    <script src="assets/js/bootstrap-tab.js"></script>
    <script src="assets/js/bootstrap-tooltip.js"></script>
    <script src="assets/js/bootstrap-popover.js"></script>
    <script src="assets/js/bootstrap-button.js"></script>
    <script src="assets/js/bootstrap-collapse.js"></script>
    <script src="assets/js/bootstrap-carousel.js"></script>
    <script src="assets/js/bootstrap-typeahead.js"></script>
    <script src="assets/js/bootstrap-affix.js"></script>
    <script src="assets/js/holder/holder.js"></script>
    <script src="assets/js/application.js"></script>
-->
